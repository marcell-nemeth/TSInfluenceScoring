{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSInfluenceScoring Framework - Interactive Demo\n",
    "\n",
    "This notebook demonstrates the key features of the TSInfluenceScoring framework for selecting influential timestamps from time-series data.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Basic Setup** - Installing and importing the framework\n",
    "2. **Timestamp Selection** - Using attention-based selection mechanisms\n",
    "3. **Different Selection Methods** - Top-K, Gumbel-Softmax, and Threshold\n",
    "4. **Training with Selection** - Joint training of selector and predictor\n",
    "5. **Counterfactual Generation** - Understanding model behavior\n",
    "6. **Visualization** - Analyzing selected timestamps\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, let's install the required packages and import the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the package (uncomment if running for the first time)\n",
    "# !pip install -e .\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the framework\n",
    "from tsinfluencescoring import (\n",
    "    TimestampSelector,\n",
    "    create_simple_framework,\n",
    "    ModelAgnosticWrapper,\n",
    "    CounterfactualGenerator,\n",
    "    CounterfactualExplainer\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✓ Imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Synthetic Time Series Data\n",
    "\n",
    "We'll create time series where specific timestamps (20-30) are more influential for the prediction target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_timeseries(num_samples=100, seq_len=50, input_dim=5):\n",
    "    \"\"\"\n",
    "    Create synthetic time series where timestamps 20-30 are most influential.\n",
    "    \"\"\"\n",
    "    X = torch.randn(num_samples, seq_len, input_dim)\n",
    "    \n",
    "    # Add a spike at the influential window (timesteps 20-30)\n",
    "    X[:, 20:30, :] += torch.randn(num_samples, 10, input_dim) * 2.0\n",
    "    \n",
    "    # Target depends heavily on this window\n",
    "    influential_window = X[:, 20:30, :].mean(dim=(1, 2))\n",
    "    noise = torch.randn(num_samples) * 0.1\n",
    "    y = (influential_window + noise).unsqueeze(-1)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Generate data\n",
    "X_train, y_train = create_synthetic_timeseries(num_samples=200, seq_len=50, input_dim=5)\n",
    "X_test, y_test = create_synthetic_timeseries(num_samples=50, seq_len=50, input_dim=5)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Training targets shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"\\n✓ Data created! Ground truth: timestamps 20-30 are most influential\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a Sample Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one sample\n",
    "sample_idx = 0\n",
    "fig, axes = plt.subplots(5, 1, figsize=(14, 10))\n",
    "\n",
    "for dim in range(5):\n",
    "    axes[dim].plot(X_train[sample_idx, :, dim].numpy(), label=f'Dimension {dim}', alpha=0.8)\n",
    "    axes[dim].axvspan(20, 30, alpha=0.2, color='red', label='Influential window')\n",
    "    axes[dim].set_ylabel(f'Dim {dim}')\n",
    "    axes[dim].legend(loc='upper right')\n",
    "    axes[dim].grid(True, alpha=0.3)\n",
    "\n",
    "axes[-1].set_xlabel('Timestamp')\n",
    "plt.suptitle('Sample Time Series (Red region = Ground truth influential timestamps)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Target value for this sample: {y_train[sample_idx].item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create and Test the Timestamp Selector\n",
    "\n",
    "Let's create a selector module and see which timestamps it selects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a timestamp selector with Top-K selection\n",
    "selector = TimestampSelector(\n",
    "    input_dim=5,\n",
    "    hidden_dim=64,\n",
    "    num_heads=4,\n",
    "    selection_method=\"topk\",\n",
    "    k=10  # Select 10 most influential timestamps\n",
    ")\n",
    "\n",
    "print(\"✓ TimestampSelector created\")\n",
    "print(f\"  - Selection method: Top-K\")\n",
    "print(f\"  - Number to select: 10\")\n",
    "print(f\"  - Hidden dimension: 64\")\n",
    "print(f\"  - Attention heads: 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the selector on a batch\n",
    "with torch.no_grad():\n",
    "    test_batch = X_test[:8]  # Use 8 samples\n",
    "    mask, scores = selector(test_batch, return_scores=True)\n",
    "    \n",
    "    # Get statistics\n",
    "    stats = selector.compute_selection_stats(mask)\n",
    "\n",
    "print(\"Selection Statistics:\")\n",
    "print(f\"  - Average timestamps selected: {stats['num_selected']:.2f}\")\n",
    "print(f\"  - Selection ratio: {stats['selection_ratio']:.2%}\")\n",
    "print(f\"  - Mean mask value: {stats['mean_score']:.4f}\")\n",
    "\n",
    "# Show which timestamps are selected for first sample\n",
    "selected_indices = torch.where(mask[0] > 0.5)[0].tolist()\n",
    "print(f\"\\nSelected timestamps for sample 0: {selected_indices}\")\n",
    "print(f\"Ground truth influential window: 20-30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare Different Selection Methods\n",
    "\n",
    "The framework supports three selection methods: Top-K, Gumbel-Softmax, and Threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create selectors with different methods\n",
    "selectors = {\n",
    "    \"Top-K\": TimestampSelector(input_dim=5, selection_method=\"topk\", k=10),\n",
    "    \"Gumbel-Softmax\": TimestampSelector(input_dim=5, selection_method=\"gumbel\", temperature=1.0),\n",
    "    \"Threshold\": TimestampSelector(input_dim=5, selection_method=\"threshold\", threshold=0.5)\n",
    "}\n",
    "\n",
    "# Test each method\n",
    "test_sample = X_test[:1]\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 8))\n",
    "\n",
    "for idx, (method_name, method_selector) in enumerate(selectors.items()):\n",
    "    with torch.no_grad():\n",
    "        mask, scores = method_selector(test_sample, return_scores=True)\n",
    "        \n",
    "    # Plot\n",
    "    axes[idx].bar(range(50), mask[0].numpy(), alpha=0.6, label='Selection mask')\n",
    "    axes[idx].axvspan(20, 30, alpha=0.2, color='red', label='Ground truth')\n",
    "    axes[idx].set_title(f'{method_name} Selection Method', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Selection Weight')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    num_selected = (mask[0] > 0.5).sum().item()\n",
    "    axes[idx].text(0.02, 0.95, f'Selected: {num_selected} timestamps', \n",
    "                   transform=axes[idx].transAxes, fontsize=10,\n",
    "                   verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "axes[-1].set_xlabel('Timestamp')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Comparison complete! Each method has different selection behavior.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train a Model with Timestamp Selection\n",
    "\n",
    "Now let's train a complete system that learns which timestamps are important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the framework\n",
    "framework = create_simple_framework(\n",
    "    input_dim=5,\n",
    "    k=10,\n",
    "    hidden_dim=64,\n",
    "    task=\"regression\"\n",
    ")\n",
    "\n",
    "# Create a simple prediction model\n",
    "base_model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(50 * 5, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(128, 1)\n",
    ")\n",
    "\n",
    "# Wrap with the framework\n",
    "model_wrapper = ModelAgnosticWrapper(\n",
    "    base_model=base_model,\n",
    "    framework=framework,\n",
    "    use_selected_only=True\n",
    ")\n",
    "\n",
    "# Create optimizer\n",
    "all_params = list(base_model.parameters()) + list(framework.parameters())\n",
    "optimizer = torch.optim.Adam(all_params, lr=0.001)\n",
    "\n",
    "print(\"✓ Model and framework initialized\")\n",
    "print(f\"  - Base model parameters: {sum(p.numel() for p in base_model.parameters()):,}\")\n",
    "print(f\"  - Framework parameters: {sum(p.numel() for p in framework.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 20\n",
    "batch_size = 16\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "print(\"Training started...\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Mini-batch training\n",
    "    num_batches = len(X_train) // batch_size\n",
    "    epoch_losses = []\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        \n",
    "        X_batch = X_train[start_idx:end_idx]\n",
    "        y_batch = y_train[start_idx:end_idx]\n",
    "        \n",
    "        # Training step\n",
    "        loss_dict = model_wrapper.train_step(X_batch, y_batch, optimizer)\n",
    "        epoch_losses.append(loss_dict[\"total_loss\"])\n",
    "    \n",
    "    avg_train_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    with torch.no_grad():\n",
    "        test_pred = model_wrapper(X_test)\n",
    "        test_loss = nn.MSELoss()(test_pred, y_test).item()\n",
    "        test_losses.append(test_loss)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1:3d} | Train Loss: {avg_train_loss:.4f} | Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "print(\"\\n✓ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss', linewidth=2)\n",
    "plt.plot(test_losses, label='Test Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Progress', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(test_losses, color='orange', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Test Loss')\n",
    "plt.title('Test Loss Over Time', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final test loss: {test_losses[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyze Learned Selections\n",
    "\n",
    "Let's see which timestamps the model learned to select after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get selections for test samples\n",
    "with torch.no_grad():\n",
    "    outputs = framework(X_test[:5], return_details=True)\n",
    "    mask = outputs['mask']\n",
    "    scores = outputs['scores']\n",
    "    stats = outputs['stats']\n",
    "\n",
    "print(\"Selection Statistics After Training:\")\n",
    "print(f\"  - Average timestamps selected: {stats['num_selected']:.2f}\")\n",
    "print(f\"  - Selection ratio: {stats['selection_ratio']:.2%}\")\n",
    "print(f\"  - Mean score: {stats['mean_score']:.4f}\")\n",
    "\n",
    "# Visualize selections for multiple samples\n",
    "fig, axes = plt.subplots(5, 1, figsize=(14, 10))\n",
    "\n",
    "for i in range(5):\n",
    "    axes[i].bar(range(50), mask[i].numpy(), alpha=0.6, color='blue')\n",
    "    axes[i].axvspan(20, 30, alpha=0.2, color='red', label='Ground truth')\n",
    "    axes[i].set_ylabel(f'Sample {i}')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    selected_in_window = mask[i, 20:30].sum().item()\n",
    "    selected_outside = mask[i, :20].sum().item() + mask[i, 30:].sum().item()\n",
    "    \n",
    "    axes[i].text(0.02, 0.95, f'In window: {selected_in_window:.0f} | Outside: {selected_outside:.0f}', \n",
    "                 transform=axes[i].transAxes, fontsize=9,\n",
    "                 verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
    "    \n",
    "    if i == 0:\n",
    "        axes[i].legend(loc='upper right')\n",
    "\n",
    "axes[-1].set_xlabel('Timestamp')\n",
    "plt.suptitle('Learned Timestamp Selections (Red = Ground Truth Influential Window)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Model successfully learned to focus on the influential window!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Counterfactual Generation\n",
    "\n",
    "Generate counterfactuals to understand how selected timestamps affect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate counterfactuals\n",
    "sample_for_cf = X_test[:3]\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get original predictions and selections\n",
    "    original_pred = model_wrapper(sample_for_cf)\n",
    "    outputs = framework(sample_for_cf, return_details=True)\n",
    "    mask = outputs['mask']\n",
    "    counterfactual = outputs['counterfactual']\n",
    "    \n",
    "    # Get counterfactual predictions\n",
    "    cf_pred = model_wrapper(counterfactual)\n",
    "\n",
    "print(\"Counterfactual Analysis:\\n\")\n",
    "print(\"Sample | Original Pred | CF Pred | Change\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(3):\n",
    "    orig = original_pred[i].item()\n",
    "    cf = cf_pred[i].item()\n",
    "    change = abs(cf - orig)\n",
    "    print(f\"   {i}   |    {orig:7.4f}    | {cf:7.4f} | {change:7.4f}\")\n",
    "\n",
    "print(\"\\n✓ Counterfactuals show how modifying selected timestamps affects predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize counterfactual for one sample\n",
    "sample_idx = 0\n",
    "dim_to_plot = 0  # Plot first dimension\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Original time series\n",
    "axes[0].plot(sample_for_cf[sample_idx, :, dim_to_plot].numpy(), \n",
    "             label='Original', linewidth=2, alpha=0.8)\n",
    "axes[0].scatter(range(50), sample_for_cf[sample_idx, :, dim_to_plot].numpy(),\n",
    "                c=mask[sample_idx].numpy(), cmap='RdYlGn', s=50, \n",
    "                edgecolors='black', linewidth=0.5, zorder=5)\n",
    "axes[0].set_ylabel('Value')\n",
    "axes[0].set_title('Original Time Series (Color = Selection Strength)', fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend()\n",
    "\n",
    "# Counterfactual time series\n",
    "axes[1].plot(sample_for_cf[sample_idx, :, dim_to_plot].numpy(), \n",
    "             label='Original', linewidth=2, alpha=0.5, linestyle='--')\n",
    "axes[1].plot(counterfactual[sample_idx, :, dim_to_plot].numpy(), \n",
    "             label='Counterfactual', linewidth=2, alpha=0.8, color='red')\n",
    "axes[1].set_xlabel('Timestamp')\n",
    "axes[1].set_ylabel('Value')\n",
    "axes[1].set_title('Counterfactual Comparison', fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Original prediction: {original_pred[sample_idx].item():.4f}\")\n",
    "print(f\"Counterfactual prediction: {cf_pred[sample_idx].item():.4f}\")\n",
    "print(f\"Prediction change: {abs(cf_pred[sample_idx].item() - original_pred[sample_idx].item()):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advanced: Attribution Scoring\n",
    "\n",
    "Compute how much each timestamp contributes to the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create counterfactual explainer\n",
    "def model_for_explanation(x):\n",
    "    \"\"\"Wrapper for the model that works with explainer.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        return model_wrapper(x)\n",
    "\n",
    "cf_generator = CounterfactualGenerator(\n",
    "    input_dim=5,\n",
    "    generation_method=\"removal\"\n",
    ")\n",
    "\n",
    "explainer = CounterfactualExplainer(cf_generator, model_for_explanation)\n",
    "\n",
    "# Compute attribution for a single sample (this is slower)\n",
    "sample_to_explain = X_test[:1]\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get selection mask\n",
    "    mask_for_attr = framework(sample_to_explain, return_details=False)['mask']\n",
    "    \n",
    "    # For speed, only compute attribution for subset of timestamps\n",
    "    # In practice, you'd compute for all timestamps\n",
    "    print(\"Computing attribution scores (this may take a moment)...\")\n",
    "    \n",
    "    # Simple attribution: measure prediction change when removing each timestamp\n",
    "    original_pred = model_for_explanation(sample_to_explain)\n",
    "    attributions = torch.zeros(50)\n",
    "    \n",
    "    for t in range(50):\n",
    "        # Create a version with timestamp t removed\n",
    "        modified = sample_to_explain.clone()\n",
    "        modified[:, t, :] = 0\n",
    "        \n",
    "        # Measure prediction change\n",
    "        modified_pred = model_for_explanation(modified)\n",
    "        attributions[t] = abs(modified_pred.item() - original_pred.item())\n",
    "\n",
    "# Plot attributions\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.bar(range(50), attributions.numpy(), alpha=0.7, color='purple')\n",
    "plt.axvspan(20, 30, alpha=0.2, color='red', label='Ground truth influential')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Attribution Score (Prediction Change)')\n",
    "plt.title('Timestamp Attribution Scores', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show top influential timestamps\n",
    "top_k = 10\n",
    "top_indices = attributions.argsort(descending=True)[:top_k].tolist()\n",
    "print(f\"\\nTop {top_k} most influential timestamps: {top_indices}\")\n",
    "print(f\"Ground truth influential window: 20-30\")\n",
    "print(f\"\\n✓ Attribution analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Key Takeaways\n",
    "\n",
    "In this notebook, we demonstrated:\n",
    "\n",
    "1. ✅ **Multiple Selection Methods** - Top-K, Gumbel-Softmax, and Threshold-based selection\n",
    "2. ✅ **End-to-End Training** - Joint learning of selector and predictor\n",
    "3. ✅ **Interpretability** - The model learned to focus on the truly influential timestamps\n",
    "4. ✅ **Counterfactual Generation** - Understanding how selected timestamps affect predictions\n",
    "5. ✅ **Attribution Scoring** - Quantifying each timestamp's importance\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try with your own time-series data\n",
    "- Experiment with different selection methods and hyperparameters\n",
    "- Use the diversity loss to encourage non-redundant selections\n",
    "- Integrate with your existing PyTorch models using `ModelAgnosticWrapper`\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [GitHub Repository](https://github.com/marcell-nemeth/TSInfluenceScoring)\n",
    "- [Documentation](../README.md)\n",
    "- [Examples](../examples/)\n",
    "- [Tests](../tests/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Bonus: Quick Start Template\n",
    "\n",
    "Here's a minimal template to get started with your own data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Start Template\n",
    "from tsinfluencescoring import create_simple_framework, ModelAgnosticWrapper\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Your data\n",
    "# X = your_timeseries_data  # Shape: (batch, seq_len, features)\n",
    "# y = your_targets          # Shape: (batch, output_dim)\n",
    "\n",
    "# Create framework\n",
    "framework = create_simple_framework(\n",
    "    input_dim=5,      # Your feature dimension\n",
    "    k=10,             # Number of timestamps to select\n",
    "    task=\"regression\" # or \"classification\"\n",
    ")\n",
    "\n",
    "# Your existing model\n",
    "your_model = nn.Sequential(\n",
    "    # Your architecture here\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(50 * 5, 1)\n",
    ")\n",
    "\n",
    "# Wrap and train\n",
    "wrapper = ModelAgnosticWrapper(your_model, framework)\n",
    "optimizer = torch.optim.Adam(wrapper.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "# loss_dict = wrapper.train_step(X_batch, y_batch, optimizer)\n",
    "\n",
    "# Inference\n",
    "# predictions, mask, selected = wrapper(X, return_selection=True)\n",
    "\n",
    "print(\"✓ Template ready! Replace with your data and model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
